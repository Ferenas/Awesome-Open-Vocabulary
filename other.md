## Datasets & Benchmarks
### Detection
|Datasets|base|novel|Tasks|
|-|-|-|-|
|COCO OVD|48|17|`det.`|
|LVIS OVD|866|337|`det.`|
|PASCAL VOC|-|20|`det.`|
|Objects365|-|365|`det.`|
|LVIS|-|1,203|`det.`|
|OpenImages|-|500|`det.`|

### Semantic Segmentation
> The OV-SS task can be evaluated with different protocols (Zero-Shot, Cross-Dataset, and Annotation-Free). In general, there is not a consensus on evaluation protocol like OV-OD. Recent papers ([TCL](https://arxiv.org/abs/2212.00785), [PACL](https://arxiv.org/abs/2212.04994)) tend to evaluate on the Annotation-Free protocol.

|Datasets|base|novel|Tasks|
|-|-|-|-|
|PASCAL VOC|-|20|`seg.`|
|PASCAL Context|-|59|`seg.`|
|PASCAL Context|-|459|`seg.`|
|ADE20k-150|-|150|`seg.`|
|ADE20k-847|-|847|`seg.`|
|COCO Stuff|-|171|`seg.`|
|Cityscapes|-|19|`seg.`|
